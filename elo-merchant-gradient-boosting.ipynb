{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import datetime\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas import DataFrame\n",
    "from scipy import stats\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "a352f1dd32d50b89622d18d40ea168ae8443e86b"
   },
   "outputs": [],
   "source": [
    "## Reading files\n",
    "\n",
    "train = pd.read_csv(\"../input/elo-merchant-category-recommendation/train.csv\")\n",
    "test = pd.read_csv(\"../input/elo-merchant-category-recommendation/test.csv\")\n",
    "# hist_txns = pd.read_csv(\"../input/historical_transactions.csv\")\n",
    "# new_txns = pd.read_csv(\"../input/new_merchant_transactions.csv\")\n",
    "# merchants = pd.read_csv(\"../input/elo-merchant-category-recommendation/merchants.csv\")\n",
    "all_txns = pd.read_csv(\"../input/transactions-data/all_txns.csv\")\n",
    "# all_txns = pd.concat([hist_txns, new_txns], ignore_index=True)\n",
    "# all_txns.to_csv(\"all_txns.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "_uuid": "27f4da953fe586f15693edbb7b8dfa49eb030829"
   },
   "outputs": [],
   "source": [
    "# print (all_txns.shape)\n",
    "\n",
    "# merchants_subset = merchants[[\"merchant_id\", \"numerical_1\", \"numerical_2\"]]\n",
    "\n",
    "# txns_plus_merchants= pd.concat([all_txns, merchants_subset], axis=1)\n",
    "\n",
    "# print (txns_plus_merchants.shape)\n",
    "# print (txns_plus_merchants.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "ee75345c44ae8a14e7cfa4ff5b02726497385886"
   },
   "outputs": [],
   "source": [
    "# print (np.unique(all_txns[\"category_1\"]))\n",
    "# print (all_txns[\"category_1\"].isna().sum())\n",
    "# print (all_txns[\"category_2\"].isna().sum())\n",
    "# print (all_txns[\"category_3\"].isna().sum())\n",
    "# print (all_txns[\"category_3\"].head(10))\n",
    "\n",
    "# indexNames = all_txns[all_txns[\"category_3\"].isna()].index\n",
    "# all_txns.drop(indexNames, inplace=True)\n",
    "# print (all_txns[\"category_3\"].isna().sum())\n",
    "# print (np.unique(all_txns[\"category_3\"]))\n",
    "\n",
    "# fill_na_with_mode = stats.mode(all_txns[\"category_3\"])\n",
    "# print (fill_na_with_mode)\n",
    "# print (np.max(all_txns[\"category_2\"]))\n",
    "# print (np.min(all_txns[\"category_2\"]))\n",
    "# print (all_txns[\"category_2\"].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "ec76e7847d1b1b77c10eb510578d89048b8b69f5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Missing values treatment\n",
    "\n",
    "# print (train.shape)\n",
    "# print (hist_txns.shape)\n",
    "# print (new_txns.shape)\n",
    "# print (all_txns.shape)\n",
    "# print (all_txns.head(5))\n",
    "# print (np.max(hist_txns[\"installments\"]))\n",
    "# print (np.min(hist_txns[\"installments\"]))\n",
    "# print (np.mean(hist_txns[\"installments\"]))\n",
    "# a = np.where(hist_txns[\"installments\"] == 999)\n",
    "# print (len(a[0]))\n",
    "\n",
    "# indexNames = hist_txns[hist_txns[\"installments\"] == 999].index\n",
    "# hist_txns.drop(indexNames, inplace=True)\n",
    "# print (np.max(hist_txns[\"installments\"]))\n",
    "# print (np.min(hist_txns[\"installments\"]))\n",
    "# print (np.mean(hist_txns[\"installments\"]))\n",
    "# b = np.where(hist_txns[\"installments\"] == 999)\n",
    "# print (len(b[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "e85d2aed7612639c396449e320965e69bb9a8aab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/groupby/groupby.py:4656: FutureWarning: using a dict with renaming is deprecated and will be removed in a future version\n",
      "  return super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           card_id      ...       category_3_C\n",
      "0  C_ID_00007093c1      ...                 24\n",
      "1  C_ID_0001238066      ...                 36\n",
      "2  C_ID_0001506ef0      ...                  0\n",
      "3  C_ID_0001793786      ...                  0\n",
      "4  C_ID_000183fdda      ...                 41\n",
      "\n",
      "[5 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "txns_subset = all_txns[[\"card_id\", \"purchase_amount\", \"month_lag\",\n",
    "                        \"installments\", \"authorized_flag\", \"category_1\", \"category_3\"]]\n",
    "# print (txns_subset.head(50))\n",
    "grouped_txns = txns_subset.groupby(\"card_id\").agg({\n",
    "    \"purchase_amount\": [np.sum, np.mean],\n",
    "    \"month_lag\": [np.sum, np.mean],\n",
    "    \"installments\": [np.sum, np.mean],\n",
    "    \"authorized_flag\": {\"Y\": lambda x: x[x == 'Y'].count(),\n",
    "                        \"N\": lambda x: x[x == 'N'].count()},\n",
    "    \"category_1\": {\"Y\": lambda x: x[x == 'Y'].count(),\n",
    "                   \"N\": lambda x: x[x == 'N'].count()},\n",
    "    \"category_3\": {\"A\": lambda x: x[x == 'A'].count(),\n",
    "                   \"B\": lambda x: x[x == 'B'].count(),\n",
    "                   \"C\": lambda x: x[x == 'C'].count()}\n",
    "})\n",
    "grouped_txns.columns = [\"_\".join(x) for x in grouped_txns.columns.ravel()]\n",
    "grouped_txns = grouped_txns.reset_index()\n",
    "# print (grouped_txns.shape)\n",
    "print (grouped_txns.head(5))\n",
    "# print (list(grouped_txns.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "592a12779962decd83ae9e19ca659fcef97108e7",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_data = train.join(grouped_txns.set_index(\"card_id\"), on=\"card_id\")\n",
    "test_data = test.join(grouped_txns.set_index(\"card_id\"), on=\"card_id\")\n",
    "\n",
    "# print (train_data.shape)\n",
    "# print (test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "99fb8297efc7be47262bc382e4fdce11e777fe1e"
   },
   "outputs": [],
   "source": [
    "# Extracting number of active months\n",
    "\n",
    "train_data['first_active_month'] = pd.to_datetime(train_data['first_active_month'])\n",
    "test_data['first_active_month'] = pd.to_datetime(test_data['first_active_month'])\n",
    "current_date = datetime.datetime.today()\n",
    "\n",
    "def _number_of_active_months(design_matrix):\n",
    "    design_matrix['number_of_active_months'] = ((current_date - design_matrix['first_active_month']) / 30.).dt.days\n",
    "    return design_matrix\n",
    "\n",
    "train_mod = _number_of_active_months(train_data)\n",
    "test_mod = _number_of_active_months(test_data)\n",
    "\n",
    "## Imputing missing values in test data\n",
    "fill_na_with_mean = np.mean(test_mod['number_of_active_months'])\n",
    "test_mod['number_of_active_months'].fillna(fill_na_with_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "7abaa4f5e808eead58de239970b1e8a7530012d0"
   },
   "outputs": [],
   "source": [
    "# Normalizing continuous features\n",
    "\n",
    "features_to_norm = ['number_of_active_months', 'month_lag_sum', 'month_lag_mean',\n",
    "                    'installments_sum', 'installments_mean', 'authorized_flag_Y',\n",
    "                    'authorized_flag_N', 'category_1_Y', 'category_1_N',\n",
    "                    'category_3_A', 'category_3_B', 'category_3_C']\n",
    "for feature in features_to_norm:\n",
    "    mean_value = np.mean(train_mod[feature])\n",
    "    stdev = np.std(train_mod[feature])\n",
    "    train_mod[feature] = train_mod[feature].apply(lambda x: (x - mean_value) / (stdev))\n",
    "    test_mod[feature] = test_mod[feature].apply(lambda x: (x - mean_value) / (stdev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "eb61f262cafe6815d6a92b99d041b550b16ea6bf"
   },
   "outputs": [],
   "source": [
    "# Creating dummies for categorical features\n",
    "\n",
    "cat_features = ['feature_1', 'feature_2', 'feature_3']\n",
    "response = ['target']\n",
    "\n",
    "def _create_dummies_for_categorical_features(design_matrix):\n",
    "    \"\"\"Create dummies for categorical features\"\"\"\n",
    "    design_matrix = pd.get_dummies(design_matrix, prefix=cat_features,\n",
    "                                   columns=cat_features)\n",
    "    return design_matrix\n",
    "\n",
    "design_matrix_train = train_mod[list(test_mod.columns) + response]\n",
    "design_matrix_test = test_mod[list(test_mod.columns)]\n",
    "\n",
    "train_with_dummies = _create_dummies_for_categorical_features(design_matrix_train)\n",
    "test_with_dummies = _create_dummies_for_categorical_features(design_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "3dcc85be94fde43f4bfe5755886f1177a67c7e7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['purchase_amount_mean', 'category_1_Y', 'category_1_N', 'month_lag_mean', 'installments_mean', 'authorized_flag_N', 'authorized_flag_Y', 'number_of_active_months', 'feature_2_1', 'feature_2_2', 'feature_2_3', 'feature_3_0', 'feature_3_1', 'category_3_A', 'category_3_B', 'category_3_C', 'feature_1_1', 'feature_1_2', 'feature_1_3', 'feature_1_4', 'feature_1_5']\n"
     ]
    }
   ],
   "source": [
    "# Defining predictors for the model\n",
    "\n",
    "predictors = ['purchase_amount_mean', 'category_1_Y', 'category_1_N',\n",
    "              'month_lag_mean', 'installments_mean',\n",
    "              'authorized_flag_N', 'authorized_flag_Y', 'number_of_active_months',\n",
    "              'feature_2_1', 'feature_2_2', 'feature_2_3', 'feature_3_0', 'feature_3_1',\n",
    "              'category_3_A', 'category_3_B', 'category_3_C',\n",
    "              'feature_1_1', 'feature_1_2', 'feature_1_3', 'feature_1_4', 'feature_1_5']\n",
    "\n",
    "# predictors = list(test_with_dummies.columns)\n",
    "# predictors.remove('card_id')\n",
    "# predictors.remove('first_active_month')\n",
    "print (predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "89c2b78f3f074a0bad07dcd50b49e33e3a4b3394",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:  1.4min remaining:  2.1min\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1          14.8000           0.0406            1.14m\n",
      "         2          14.7256           0.0379            1.13m\n",
      "         3          14.8202           0.0262            1.11m\n",
      "         4          14.7068           0.0294            1.09m\n",
      "         5          14.7860           0.0228            1.08m\n",
      "         6          14.7343           0.0215            1.05m\n",
      "         7          14.5320           0.0195            1.05m\n",
      "         8          14.6440           0.0145            1.05m\n",
      "         9          14.5452           0.0160            1.04m\n",
      "        10          14.3007           0.0165            1.03m\n",
      "        20          14.2559           0.0031           53.46s\n",
      "        30          14.1883           0.0003           43.24s\n",
      "        40          14.3069          -0.0018           32.82s\n",
      "        50          14.0039          -0.0024           22.18s\n",
      "        60          13.8321          -0.0041           12.90s\n",
      "        70          13.9586          -0.0010            4.21s\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.075, loss='ls', max_depth=6,\n",
      "             max_features='auto', max_leaf_nodes=None,\n",
      "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "             min_samples_leaf=4, min_samples_split=2,\n",
      "             min_weight_fraction_leaf=0.0, n_estimators=75,\n",
      "             n_iter_no_change=20, presort='auto', random_state=9,\n",
      "             subsample=0.8, tol=0.0001, validation_fraction=0.1, verbose=1,\n",
      "             warm_start=True)\n",
      "Best model score:  -14.470508025669341\n"
     ]
    }
   ],
   "source": [
    "# Model assessment using cross-validation\n",
    "\n",
    "regressor = GradientBoostingRegressor()\n",
    "parameters = {\n",
    "              'loss': ['ls'],\n",
    "              'learning_rate': [0.075],\n",
    "              'n_estimators': [75],\n",
    "              'subsample': [0.8],\n",
    "              'criterion': ['friedman_mse'],\n",
    "              'max_depth': [6],\n",
    "              'min_samples_split': [2],\n",
    "              'max_features': ['auto'],\n",
    "              'warm_start': [True],\n",
    "              'random_state': [9],\n",
    "              'min_samples_leaf': [4],\n",
    "              'verbose': [1],\n",
    "              'n_iter_no_change': [20]\n",
    "             }\n",
    "\n",
    "model_grid = GridSearchCV(regressor,\n",
    "                          param_grid=parameters,\n",
    "                          scoring= \"neg_mean_squared_error\",\n",
    "                          cv=5,\n",
    "                          verbose=1,\n",
    "                          n_jobs=5,\n",
    "                          iid=False\n",
    "                         )\n",
    "\n",
    "model_grid.fit(train_with_dummies[predictors], train_with_dummies['target'])\n",
    "print (model_grid.best_estimator_)\n",
    "print ('Best model score: ', model_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "c28686bec479a79b4cc7264d3f1b3c1c132e715b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  param_max_depth       ...       mean_test_score\n",
      "0               6       ...            -14.470508\n",
      "\n",
      "[1 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation results\n",
    "\n",
    "cv_results = model_grid.cv_results_\n",
    "results = DataFrame.from_dict(cv_results, orient='columns')\n",
    "results.sort_values(['mean_test_score'], ascending=False, inplace=True)\n",
    "# results.to_csv('GridSearch_results_4.csv', index=False)\n",
    "print (results[['param_max_depth', 'param_min_samples_split',\n",
    "                'param_min_samples_leaf', 'mean_test_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "a930db911ed1f711b7b109994085494888377656"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  3.8040120958889365\n"
     ]
    }
   ],
   "source": [
    "## Validation using best estimator\n",
    "\n",
    "# best_model = model_grid.best_estimator_\n",
    "# print ('Out of bag training score: ', best_model.oob_score_)\n",
    "# validation_data['target_predicted'] = best_model.predict(validation_data[predictors])\n",
    "# validation_data.to_csv('validation_data.csv', index=False)\n",
    "\n",
    "# RMSE\n",
    "mean_squared_error = (-1.) * model_grid.best_score_\n",
    "rmse = np.sqrt(mean_squared_error)\n",
    "print ('RMSE: ', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "30e078ffa0130f3359505fe0518402b97d785d7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "                                0\n",
      "month_lag_mean           0.235734\n",
      "number_of_active_months  0.154359\n",
      "category_1_Y             0.119589\n",
      "authorized_flag_N        0.104924\n",
      "purchase_amount_mean     0.078704\n",
      "installments_mean        0.075226\n",
      "authorized_flag_Y        0.067788\n",
      "category_1_N             0.052338\n",
      "category_3_B             0.046087\n",
      "category_3_C             0.023533\n",
      "category_3_A             0.017775\n",
      "feature_2_3              0.007680\n",
      "feature_1_2              0.003335\n",
      "feature_1_3              0.002432\n",
      "feature_2_1              0.002012\n",
      "feature_1_4              0.001838\n",
      "feature_2_2              0.001638\n",
      "feature_1_5              0.001410\n",
      "feature_3_1              0.001239\n",
      "feature_1_1              0.001203\n",
      "feature_3_0              0.001156\n",
      "\n",
      "Model score:  0.06339098739279514\n"
     ]
    }
   ],
   "source": [
    "# Fitting model with the best (chosen) estimator\n",
    "\n",
    "best_model = model_grid.best_estimator_\n",
    "model = best_model.fit(train_with_dummies[predictors], train_with_dummies['target'])\n",
    "feature_imp1 = dict(zip(predictors, model.feature_importances_))\n",
    "feature_imp2 = DataFrame.from_dict(feature_imp1, orient='index')\n",
    "feature_imp2.sort_values([0], ascending=False, inplace=True)\n",
    "print (feature_imp2.head(30))\n",
    "# print ('Feature intercept: ', model.intercept_)\n",
    "\n",
    "# Model score\n",
    "score = best_model.score(train_with_dummies[predictors], train_with_dummies['target'])\n",
    "print ()\n",
    "print ('Model score: ', score)\n",
    "\n",
    "# Predictions on test data\n",
    "test_with_dummies['target'] = model.predict(test_with_dummies[predictors])\n",
    "# print (test_with_dummies.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Submissions\n",
    "\n",
    "submission_file = test_with_dummies[['card_id', 'target']]\n",
    "# print (submission_file.head(20))\n",
    "\n",
    "submission_file.to_csv('submission_22_' + str(rmse) + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
