{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movielens model\n",
    "In this notebook we build a movie recomandation model using movielens dataset.\n",
    "The model uses entity embeddings for categorical variables from [this paper](https://arxiv.org/abs/1604.06737) to embedd users and movies into two 50 dimensional spaces.\n",
    "Hence we have 3 methods to recomand movies: \n",
    "1. evaluating the model,\n",
    "2. look at close neighbords of a movie in the embedding space,\n",
    "3. look at close neighbords of a user in the embedding space, and recomand those top movies.\n",
    "\n",
    "The code woarks on Linux and Windows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# from movienet import MovieNet\n",
    "\n",
    "from keras.models import load_model, model_from_json\n",
    "from keras.models import Model as KerasModel\n",
    "from keras.layers import Input, Dense, Activation, Reshape, Dropout\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "class MovieNet: \n",
    "    def rmse(self, y, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y)))\n",
    "\n",
    "    def custom_activation(self, x):\n",
    "        return K.sigmoid(x) * (self.max_rating+1)\n",
    "\n",
    "    def __init__(self, n_users, n_movies, min_rating=0.5, max_rating=5):\n",
    "        self.min_rating = min_rating\n",
    "        self.max_rating = max_rating\n",
    "        self.n_users = n_users\n",
    "        self.n_movies = n_movies\n",
    "        \n",
    "    def build_model(self, emb_size=[50, 50], hl=[10], drop=[0.25], emb_trainable=True):\n",
    "        inputs = [Input(shape=(1,)), Input(shape=(1,))] #, Input(shape=(1,))]\n",
    "        users_emb = Embedding(self.n_users, emb_size[0], name='users', trainable=emb_trainable)(inputs[0])\n",
    "        movies_emb = Embedding(self.n_movies, emb_size[1], name='movies', trainable=emb_trainable)(inputs[1])\n",
    "        outputs_emb = [Reshape(target_shape=(emb_size[0],))(users_emb), Reshape(target_shape=(emb_size[1],))(movies_emb)]\n",
    "        \n",
    "        output_model = Concatenate()(outputs_emb)\n",
    "        for i in range(0, len(hl)):\n",
    "            output_model = Dense(hl[i], kernel_initializer='uniform')(output_model)\n",
    "            output_model = Activation('relu')(output_model)\n",
    "            output_model = Dropout(drop[i])(output_model)\n",
    "\n",
    "        output_model = Dense(1)(output_model)\n",
    "\n",
    "        output_model = Activation(self.custom_activation)(output_model)\n",
    "        \n",
    "        self.model = KerasModel(inputs=inputs, outputs=output_model)\n",
    "        \n",
    "        opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "        \n",
    "        self.model.compile(loss='mse', optimizer=opt, metrics=[self.rmse])\n",
    "        \n",
    "          \n",
    "    def prepare_input(self, _X):\n",
    "        X = [_X.userId.values, _X.movieId.values]#, _X.ratingWeight]\n",
    "        return X            \n",
    "            \n",
    "    def evaluate(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return mean_squared_error(y, y_pred)\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_valid, y_valid, epochs=50, batch_size=32, verbose=1):\n",
    "        self.model.fit(self.prepare_input(X_train), y_train,\n",
    "                       validation_data=(self.prepare_input(X_valid), y_valid),\n",
    "                      epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "        # print(\"Result on validation data: \", self.evaluate(X_valid, y_valid))\n",
    "        \n",
    "    def predict(self, X):\n",
    "        y_pred = self.model.predict(self.prepare_input(X))\n",
    "        return y_pred.flatten()\n",
    "\n",
    "    def save_model(self, path=Path(\"\"), name=\"MovieModel\"):\n",
    "        self.model.save_weights(path/str(name+\"_weights.h5\"))\n",
    "        with open(path/str(name+'_arch.json'), 'w') as f:\n",
    "            f.write(self.model.to_json())\n",
    "    \n",
    "    def load_model(self, path=Path(\"\"), name=\"MovieModel\"):\n",
    "        with open(path/str(name +'_arch.json'), 'r') as f:\n",
    "            self.model = model_from_json(f.read(), custom_objects={\"custom_activation\": self.custom_activation})\n",
    "        self.model.load_weights(path/str(name+\"_weights.h5\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = Path(\"data/ml-latest-small\")\n",
    "# PATH = Path(\"data/ml-20m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'F:/recommender_jk/movielens/ml-20m/ml-20m/'\n",
    "ratings_raw = pd.read_csv(data_path + '/ratings.csv')\n",
    "movies_raw = pd.read_csv(data_path + '/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112486027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1        2     3.5  1112486027\n",
       "1       1       29     3.5  1112484676\n",
       "2       1       32     3.5  1112484819\n",
       "3       1       47     3.5  1112484727\n",
       "4       1       50     3.5  1112484580"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ratings_raw.head())\n",
    "display(movies_raw.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features engineering\n",
    "The datasets are clean, we only creating dictionnaries to convert ids and indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_train = ratings_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dictionaries to convert userId and movieId into index and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138493, 26744)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_uniq = ratings_train.userId.unique()\n",
    "user2idx = {o:i for i,o in enumerate(users_uniq)}\n",
    "idx2user = {i:o for i,o in enumerate(users_uniq)}\n",
    "ratings_train.userId = ratings_train.userId.apply(lambda x: user2idx[x])\n",
    "\n",
    "movies_uniq = ratings_train.movieId.unique()\n",
    "movie2idx = {o:i for i,o in enumerate(movies_uniq)}\n",
    "idx2movie = {i:o for i,o in enumerate(movies_uniq)}\n",
    "ratings_train.movieId = ratings_train.movieId.apply(lambda x: movie2idx[x])\n",
    "\n",
    "n_users = int(ratings_train.userId.nunique())\n",
    "n_movies = int(ratings_train.movieId.nunique())\n",
    "n_users, n_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112486027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       0        0     3.5  1112486027\n",
       "1       0        1     3.5  1112484676\n",
       "2       0        2     3.5  1112484819\n",
       "3       0        3     3.5  1112484727\n",
       "4       0        4     3.5  1112484580"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name):  \n",
    "    with open('./model' + name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "save_obj(user2idx, \"user2idx\")\n",
    "save_obj(idx2user, \"idx2user\")\n",
    "save_obj(movie2idx, \"movie2idx\")\n",
    "save_obj(idx2movie, \"idx2movie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model\n",
    "The model works as follows:\n",
    "1. Embedds the user and movie id.\n",
    "2. Concanate the user embedding, movie embedding and the weighted rating into one vector.\n",
    "3. Passes to linear layers with dropout.\n",
    "\n",
    "The architecture takes as parameters the embedding size, the size of hidden layers, and the dropout probability associate to them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting data into train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_model = MovieNet(n_users, n_movies)\n",
    "movie_model.build_model(emb_size=[50, 50], hl=[70, 10], drop=[0.4, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000210, 4000053, 16000210, 4000053)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = ratings_train.drop(['timestamp', 'rating'], axis=1)\n",
    "y = ratings_train['rating']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "len(X_train), len(X_valid), len(y_train), len(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important that every movie are in the training set to have trained embedding of each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25829, 26744, 915)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[\"movieId\"].unique()), n_movies, n_movies - len(X_train[\"movieId\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_movies = ratings_train[~ratings_train.movieId.isin(X_train[\"movieId\"].unique())][\"movieId\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = pd.DataFrame()\n",
    "for i in miss_movies:\n",
    "    concat = concat.append(ratings_train[ratings_train.movieId == i].sample(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65472</th>\n",
       "      <td>458</td>\n",
       "      <td>7277</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1337498446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146083</th>\n",
       "      <td>978</td>\n",
       "      <td>9658</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1420447834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254883</th>\n",
       "      <td>1754</td>\n",
       "      <td>10647</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1370447115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387761</th>\n",
       "      <td>2649</td>\n",
       "      <td>11621</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1422306879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387843</th>\n",
       "      <td>2649</td>\n",
       "      <td>11652</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1347585021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating   timestamp\n",
       "65472      458     7277     3.5  1337498446\n",
       "146083     978     9658     0.5  1420447834\n",
       "254883    1754    10647     1.0  1370447115\n",
       "387761    2649    11621     4.5  1422306879\n",
       "387843    2649    11652     4.5  1347585021"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_valid.drop(concat.index, axis=0, inplace=True)\n",
    "y_valid.drop(concat.index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, concat.drop([\"rating\", \"timestamp\"], axis=1)])\n",
    "y_train = pd.concat([y_train, concat[\"rating\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26744, 26744)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[\"movieId\"].unique()), n_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16001125 samples, validate on 3999138 samples\n",
      "Epoch 1/5\n",
      "16001125/16001125 [==============================] - 564s 35us/step - loss: 0.7745 - rmse: 0.8791 - val_loss: 0.7021 - val_rmse: 0.8373\n",
      "Epoch 2/5\n",
      "16001125/16001125 [==============================] - 562s 35us/step - loss: 0.7224 - rmse: 0.8493 - val_loss: 0.6854 - val_rmse: 0.8273\n",
      "Epoch 3/5\n",
      "16001125/16001125 [==============================] - 560s 35us/step - loss: 0.7046 - rmse: 0.8388 - val_loss: 0.6755 - val_rmse: 0.8212\n",
      "Epoch 4/5\n",
      "16001125/16001125 [==============================] - 562s 35us/step - loss: 0.6913 - rmse: 0.8308 - val_loss: 0.6692 - val_rmse: 0.8174\n",
      "Epoch 5/5\n",
      "16001125/16001125 [==============================] - 561s 35us/step - loss: 0.6806 - rmse: 0.8244 - val_loss: 0.6648 - val_rmse: 0.8147\n"
     ]
    }
   ],
   "source": [
    "movie_model.fit(X_train, y_train, X_valid, y_valid, epochs=5, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_model.save_model(name=\"movie_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16001125 samples, validate on 3999138 samples\n",
      "Epoch 1/1\n",
      " 2124800/16001125 [==>...........................] - ETA: 8:02 - loss: 0.6625 - rmse: 0.8133"
     ]
    }
   ],
   "source": [
    "movie_model.fit(X_train, y_train, X_valid, y_valid, epochs=1, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_model.save_model(name=\"movie_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16001141 samples, validate on 3999122 samples\n",
      "Epoch 1/12\n",
      "16001141/16001141 [==============================] - 1958s 122us/step - loss: 0.6871 - rmse: 0.8265 - val_loss: 0.6639 - val_rmse: 0.8123\n",
      "Epoch 2/12\n",
      "16001141/16001141 [==============================] - 1954s 122us/step - loss: 0.6815 - rmse: 0.8231 - val_loss: 0.6648 - val_rmse: 0.8130\n",
      "Epoch 3/12\n",
      "16001141/16001141 [==============================] - 1959s 122us/step - loss: 0.6755 - rmse: 0.8194 - val_loss: 0.6632 - val_rmse: 0.8121\n",
      "Epoch 4/12\n",
      "16001141/16001141 [==============================] - 1959s 122us/step - loss: 0.6703 - rmse: 0.8162 - val_loss: 0.6538 - val_rmse: 0.8061\n",
      "Epoch 5/12\n",
      "16001141/16001141 [==============================] - 1953s 122us/step - loss: 0.6660 - rmse: 0.8137 - val_loss: 0.6498 - val_rmse: 0.8036\n",
      "Epoch 6/12\n",
      "16001141/16001141 [==============================] - 1953s 122us/step - loss: 0.6626 - rmse: 0.8115 - val_loss: 0.6507 - val_rmse: 0.8041\n",
      "Epoch 7/12\n",
      "16001141/16001141 [==============================] - 1956s 122us/step - loss: 0.6589 - rmse: 0.8092 - val_loss: 0.6491 - val_rmse: 0.8032\n",
      "Epoch 8/12\n",
      "16001141/16001141 [==============================] - 1954s 122us/step - loss: 0.6560 - rmse: 0.8075 - val_loss: 0.6476 - val_rmse: 0.8022\n",
      "Epoch 9/12\n",
      "16001141/16001141 [==============================] - 1955s 122us/step - loss: 0.6531 - rmse: 0.8057 - val_loss: 0.6517 - val_rmse: 0.8049\n",
      "Epoch 10/12\n",
      "16001141/16001141 [==============================] - 1955s 122us/step - loss: 0.6507 - rmse: 0.8042 - val_loss: 0.6502 - val_rmse: 0.8039\n",
      "Epoch 11/12\n",
      "16001141/16001141 [==============================] - 1951s 122us/step - loss: 0.6486 - rmse: 0.8029 - val_loss: 0.6471 - val_rmse: 0.8020\n",
      "Epoch 12/12\n",
      "16001141/16001141 [==============================] - 1955s 122us/step - loss: 0.6463 - rmse: 0.8015 - val_loss: 0.6501 - val_rmse: 0.8038\n"
     ]
    }
   ],
   "source": [
    "movie_model.fit(X_train, y_train, X_valid, y_valid, epochs=12, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_model.save_model(name=\"movie_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current state of the art models uses either [matrix factorization](https://docs.treasuredata.com/articles/hivemall-movielens20m-fm) with RMSE of 0.80 or [autoencoders](https://arxiv.org/pdf/1606.07659.pdf) with RMSE of 0.81.\n",
    "\n",
    "**Our model has a RMSE of ~0.80, on par with state of the art models.\n",
    "The approach of entity embeddings is simple but efficient.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
