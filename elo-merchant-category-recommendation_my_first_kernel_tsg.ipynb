{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://www.kaggle.com/chauhuynh/my-first-kernel-3-699"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import gc\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import log_loss\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RANDOM_STATE_TSG = 10007\n",
    "np.random.seed(RANDOM_STATE_TSG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'F:/github_me_repos/Kaggle_code/elo-merchant-category-recommendation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('./train_first_kernel.csv')\n",
    "df_test = pd.read_csv('./test_first_kernel.csv')\n",
    "\n",
    "print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1.519551e+09\n",
       "1     1.517438e+09\n",
       "2     1.519759e+09\n",
       "3     1.519818e+09\n",
       "4     1.519850e+09\n",
       "5     1.501343e+09\n",
       "6     1.519402e+09\n",
       "7     1.513885e+09\n",
       "8     1.512825e+09\n",
       "9     1.519837e+09\n",
       "10    1.519369e+09\n",
       "11    1.514577e+09\n",
       "12    1.519021e+09\n",
       "13    1.508012e+09\n",
       "14    1.509404e+09\n",
       "15    1.519480e+09\n",
       "16    1.519798e+09\n",
       "17    1.517915e+09\n",
       "18    1.517765e+09\n",
       "19    1.519497e+09\n",
       "Name: hist_purchase_date_max, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape\n",
    "# df_train['hist_purchase_date_max'].head(20)\n",
    "# df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199710\n",
       "1      2207\n",
       "Name: outliers, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train_no_outliers = df_train[df_train['outliers']==0]\n",
    "df_train['outliers'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/adarshchavakula/out-of-fold-oof-model-cross-validation\n",
    "\n",
    "# # Read Data\n",
    "# print(\"Reading Dataset...\")\n",
    "# train = pd.read_csv(\"../input/train.csv\")\n",
    "# target = np.array(train[\"target\"])\n",
    "# target_log = np.log1p(target) # Log transform target as the evaluation metric uses it\n",
    "# xtrain = np.array(train.iloc[:,2:])\n",
    "# print(\"Shape of training data: {}\".format(np.shape(xtrain)))\n",
    "\n",
    "# # Define Model \n",
    "# xgb_model = XGBRegressor(max_depth=6, learning_rate=0.1, n_estimators=70,\n",
    "#                          min_child_weight=100, subsample=1.0, \n",
    "#                          colsample_bytree=0.8, colsample_bylevel=0.8,\n",
    "#                          random_state=42, n_jobs=4)\n",
    "\n",
    "# # Make OOF predictions using 5 folds\n",
    "# print(\"Cross Validating...\")\n",
    "# oof_preds_log = cross_val_predict(xgb_model, xtrain, target_log, cv=5, \n",
    "#                                   n_jobs=1, method=\"predict\")\n",
    "                                  \n",
    "# # Calculate RMSLE (RMSE of Log(1+y))\n",
    "# cv_rmsle = np.sqrt(mean_squared_error(target_log, oof_preds_log))\n",
    "# print(\"\\nOOF RMSLE Score: {:.4f}\".format(cv_rmsle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 0\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0445171\tvalid_1's binary_logloss: 0.0471901\n",
      "[200]\ttraining's binary_logloss: 0.0445063\tvalid_1's binary_logloss: 0.0471852\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's binary_logloss: 0.0444367\tvalid_1's binary_logloss: 0.0471405\n",
      "auc is  0.8715427047639518\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0445582\tvalid_1's binary_logloss: 0.0454151\n",
      "[200]\ttraining's binary_logloss: 0.0445547\tvalid_1's binary_logloss: 0.0454116\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.0445184\tvalid_1's binary_logloss: 0.0453669\n",
      "auc is  0.8782335510650503\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0446811\tvalid_1's binary_logloss: 0.0442317\n",
      "[200]\ttraining's binary_logloss: 0.0446659\tvalid_1's binary_logloss: 0.0442\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's binary_logloss: 0.0446189\tvalid_1's binary_logloss: 0.044195\n",
      "auc is  0.8785598396861815\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0434702\tvalid_1's binary_logloss: 0.0493493\n",
      "[200]\ttraining's binary_logloss: 0.0434824\tvalid_1's binary_logloss: 0.0493805\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.0434288\tvalid_1's binary_logloss: 0.0493039\n",
      "auc is  0.8738629718734597\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.044839\tvalid_1's binary_logloss: 0.0448535\n",
      "[200]\ttraining's binary_logloss: 0.0448062\tvalid_1's binary_logloss: 0.044828\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's binary_logloss: 0.0447996\tvalid_1's binary_logloss: 0.0447566\n",
      "auc is  0.8757006327231831\n",
      "CV score: 0.04615 \n",
      "final auc is  0.8738057712001387\n",
      "outlier_num is  1351\n",
      "len of outlier_id is  1351 first 20 of outlier_id is  ['C_ID_afbfc01b49', 'C_ID_922f9c5ea6', 'C_ID_dc60219f6c', 'C_ID_02871a2207', 'C_ID_767923bdb9', 'C_ID_be92f84f5c', 'C_ID_cde027fde7', 'C_ID_fdf63e6d6e', 'C_ID_df36580698', 'C_ID_8cd28c90be', 'C_ID_647901f731', 'C_ID_c153fbd69e', 'C_ID_553872d9e3', 'C_ID_6e089361a2', 'C_ID_f09b0628b7', 'C_ID_43ee70f193', 'C_ID_92df9b9d44', 'C_ID_a4dfae60b0', 'C_ID_9c760806b5', 'C_ID_4299911620']\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE_TSG = 10007\n",
    "target = df_train['outliers']\n",
    "\n",
    "features = [c for c in df_train.columns if c not in ['card_id', 'first_active_month','outliers', 'target']]\n",
    "features_old = features\n",
    "features = list(df_train[features].select_dtypes(include=['number', 'bool']).columns.values)  # 去除非数值、非布尔类型数据\n",
    "# categorical_feats = [c for c in features if 'feature_' in c]\n",
    "\n",
    "categorical_feats = []\n",
    "print(len(features), len(categorical_feats))\n",
    "\n",
    "param_classifier = {\n",
    "         'num_leaves': 31,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'binary',\n",
    "         'max_depth': 6,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"rf\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'binary_logloss',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"random_state\": 2333\n",
    "}\n",
    "\n",
    "\n",
    "param_regressor = {\n",
    "         'num_leaves': 31,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'regression',\n",
    "         'max_depth': 6,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"rf\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"random_state\": 2333\n",
    "}\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE_TSG)\n",
    "# folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof = np.zeros(len(df_train))\n",
    "predictions = np.zeros(len(df_test))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train.values, df_train['outliers'].values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    \n",
    "    # 训练一个分类器 决定是否为 outlier\n",
    "    trn_data = lgb.Dataset(df_train.iloc[trn_idx][features], label=df_train['outliers'].iloc[trn_idx], categorical_feature=categorical_feats)\n",
    "    val_data = lgb.Dataset(df_train.iloc[val_idx][features], label=df_train['outliers'].iloc[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n",
    "    oof[val_idx] = clf.predict(df_train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "    auc = roc_auc_score(target.iloc[val_idx], oof[val_idx])\n",
    "    print('auc is ', auc)\n",
    "    \n",
    "#     fold_importance_df = pd.DataFrame()\n",
    "#     fold_importance_df[\"feature\"] = features\n",
    "#     fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "#     fold_importance_df[\"fold\"] = fold_ + 1\n",
    "#     feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(df_test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.5f}\".format(log_loss(target, oof)))\n",
    "print('final auc is ', roc_auc_score(target, oof))\n",
    "\n",
    "# CV score: 0.04615 \n",
    "# final auc is  0.8738057712001387\n",
    "\n",
    "predictions_is_outlier = pd.DataFrame({\"card_id\": df_test[\"card_id\"].values})\n",
    "outlier_num = int(df_train['outliers'].mean()*df_test.shape[0])  # outlier 个数\n",
    "print('outlier_num is ', outlier_num)\n",
    "predictions_is_outlier['target'] =  predictions\n",
    "\n",
    "outlier_id = list(predictions_is_outlier.sort_values(by='target',ascending = False).head(outlier_num)['card_id'])\n",
    "print('len of outlier_id is ', len(outlier_id), 'first 20 of outlier_id is ', outlier_id[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE_TSG = 10007\n",
    "target = df_train['outliers']\n",
    "\n",
    "features = [c for c in df_train.columns if c not in ['card_id', 'first_active_month','outliers', 'target']]\n",
    "features = list(df_train[features].select_dtypes(include=['number', 'bool']).columns.values)  # 去除非数值、非布尔类型数据\n",
    "# categorical_feats = [c for c in features if 'feature_' in c]\n",
    "\n",
    "categorical_feats = []\n",
    "print(len(features), len(categorical_feats))\n",
    "\n",
    "param_classifier = {\n",
    "         'num_leaves': 31,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'binary',\n",
    "         'max_depth': 6,\n",
    "         'learning_rate': 0.01,\n",
    "         \"boosting\": \"rf\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'binary_logloss',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"random_state\": 2333\n",
    "}\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE_TSG)\n",
    "# folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof = np.zeros(len(df_train))\n",
    "predictions = np.zeros(len(df_test))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train.values, df_train['outliers'].values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    \n",
    "    # 训练一个分类器 决定是否为 outlier\n",
    "    trn_data = lgb.Dataset(df_train.iloc[trn_idx][features], label=df_train['outliers'].iloc[trn_idx], categorical_feature=categorical_feats)\n",
    "    val_data = lgb.Dataset(df_train.iloc[val_idx][features], label=df_train['outliers'].iloc[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n",
    "    oof[val_idx] = clf.predict(df_train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "    auc = roc_auc_score(target.iloc[val_idx], oof[val_idx])\n",
    "    print('auc is ', auc)\n",
    "    \n",
    "#     fold_importance_df = pd.DataFrame()\n",
    "#     fold_importance_df[\"feature\"] = features\n",
    "#     fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "#     fold_importance_df[\"fold\"] = fold_ + 1\n",
    "#     feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(df_test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.5f}\".format(log_loss(target, oof)))\n",
    "print('final auc is ', roc_auc_score(target, oof))\n",
    "\n",
    "# CV score: 0.04615 \n",
    "# final auc is  0.8738057712001387\n",
    "\n",
    "predictions_is_outlier = pd.DataFrame({\"card_id\": df_test[\"card_id\"].values})\n",
    "outlier_num = int(df_train['outliers'].mean()*df_test.shape[0])  # outlier 个数\n",
    "print('outlier_num is ', outlier_num)\n",
    "predictions_is_outlier['target'] =  predictions\n",
    "\n",
    "outlier_id = list(predictions_is_outlier.sort_values(by='target',ascending = False).head(outlier_num)['card_id'])\n",
    "print('len of outlier_id is ', len(outlier_id), 'first 20 of outlier_id is ', outlier_id[:20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
